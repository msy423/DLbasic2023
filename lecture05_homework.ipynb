{"nbformat":4,"nbformat_minor":0,"metadata":{"accelerator":"GPU","colab":{"provenance":[],"gpuType":"T4"},"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.7.4"},"gpuClass":"standard"},"cells":[{"cell_type":"markdown","metadata":{"id":"MUWcdth_khfN"},"source":["# 第5回講義 宿題"]},{"cell_type":"markdown","metadata":{"id":"gAjuP7I4lWyn"},"source":["## 課題\n","\n","今Lessonで学んだことに工夫を加えて，CNNでより高精度なCIFAR10の分類器を実装してみましょう．精度上位者はリーダーボードに載ります．"]},{"cell_type":"markdown","metadata":{"id":"Cpiz19GRlZ_9"},"source":["### 目標値\n","\n","Accuracy 78%"]},{"cell_type":"markdown","metadata":{"id":"qSHeI_utleEN"},"source":["### ルール\n","\n","- 訓練データはx_train， t_train，テストデータはx_testで与えられます．\n","- 予測ラベルは one_hot表現ではなく0~9のクラスラベル で表してください．\n","- **下のセルで指定されているx_train，t_train以外の学習データは使わないでください．**\n","- 今回から基本的にAPI制限はありません．\n","- ただしCNNベースでないモデル（Vision Transformerなど）やtorchvision等の既存モデル，学習済みモデルは用いないでください．"]},{"cell_type":"markdown","metadata":{"id":"diuec-_YluI6"},"source":["### 提出方法\n","\n","- 2つのファイルを提出していただきます．\n","  - テストデータ (x_test) に対する予測ラベルをcsvファイル (ファイル名: submission_pred.csv) で提出してください．\n","  - それに対応するpythonのコードをsubmission_code.pyとして提出してください (%%writefileコマンドなどを利用してください)．"]},{"cell_type":"markdown","metadata":{"id":"hofSzJsVlvKp"},"source":["### 評価方法\n","\n","- 予測ラベルのt_testに対する精度 (Accuracy) で評価します．\n","- 提出後即時採点を行い，Leader Boardが更新されます．\n","- 締切後の点数を最終的な評価とします．"]},{"cell_type":"code","source":["# ドライブのマウント\n","from google.colab import drive\n","drive.mount('/content/drive')"],"metadata":{"id":"8dS-Kfw6fBxm","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1684601316231,"user_tz":-540,"elapsed":31923,"user":{"displayName":"村本雅弥","userId":"04864828231714976662"}},"outputId":"5416719e-1bb2-4f04-ee2c-e4500d51860a"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Mounted at /content/drive\n"]}]},{"cell_type":"markdown","metadata":{"id":"Cu4cmQtelx19"},"source":["### データの読み込み\n","\n","- この部分は修正しないでください"]},{"cell_type":"code","metadata":{"id":"EsLDDSUJkRx-"},"source":["import random\n","\n","import numpy as np\n","import pandas as pd\n","import torch\n","from torchvision import transforms\n","from tqdm import tqdm_notebook as tqdm\n","from PIL import Image\n","from sklearn.model_selection import train_test_split\n","\"\"\"\n","#学習データ\n","x_train = np.load('drive/MyDrive/Colab Notebooks/DLBasics2023_colab/Lecture05/data/x_train.npy')\n","t_train = np.load('drive/MyDrive/Colab Notebooks/DLBasics2023_colab/Lecture05/data/t_train.npy')\n","    \n","#テストデータ\n","x_test = np.load('drive/MyDrive/Colab Notebooks/DLBasics2023_colab/Lecture05/data/x_test.npy')\n","\"\"\"\n","\n","#学習データ\n","x_train = np.load('drive/MyDrive/Colab Notebooks/DeepLearning/Lecture05/data/x_train.npy')\n","t_train = np.load('drive/MyDrive/Colab Notebooks/DeepLearning/Lecture05/data/t_train.npy')\n","    \n","#テストデータ\n","x_test = np.load('drive/MyDrive/Colab Notebooks/DeepLearning/Lecture05/data/x_test.npy')\n","class train_dataset(torch.utils.data.Dataset):\n","    def __init__(self, x_train, t_train):\n","        data = x_train.astype('float32')\n","        self.x_train = []\n","        for i in range(data.shape[0]):\n","            self.x_train.append(Image.fromarray(np.uint8(data[i])))\n","        self.t_train = t_train\n","        self.transform = transforms.ToTensor()\n","\n","    def __len__(self):\n","        return len(self.x_train)\n","\n","    def __getitem__(self, idx):\n","        return self.transform(self.x_train[idx]), torch.tensor(t_train[idx], dtype=torch.long)\n","\n","class test_dataset(torch.utils.data.Dataset):\n","    def __init__(self, x_test):\n","        data = x_test.astype('float32')\n","        self.x_test = []\n","        for i in range(data.shape[0]):\n","            self.x_test.append(Image.fromarray(np.uint8(data[i])))\n","        self.transform = transforms.ToTensor()\n","\n","    def __len__(self):\n","        return len(self.x_test)\n","\n","    def __getitem__(self, idx):\n","        return self.transform(self.x_test[idx])\n","\n","trainval_data = train_dataset(x_train, t_train)\n","test_data = test_dataset(x_test)"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"UrSpHDIWOfK_"},"source":["### 畳み込みニューラルネットワーク(CNN)の実装"]},{"cell_type":"code","metadata":{"id":"sKAe0F36nSvU","executionInfo":{"status":"ok","timestamp":1684601341789,"user_tz":-540,"elapsed":14822,"user":{"displayName":"村本雅弥","userId":"04864828231714976662"}},"colab":{"base_uri":"https://localhost:8080/"},"outputId":"a34c891c-a84f-4505-a08c-988b448d26df"},"source":["def fix_seed(seed=1234):\n","    random.seed(seed)\n","    np.random.seed(seed)\n","    torch.manual_seed(seed)\n","\n","\n","fix_seed(seed=42)\n","\n","\n","class gcn():\n","    def __init__(self):\n","        pass\n","\n","    def __call__(self, x):\n","        mean = torch.mean(x)\n","        std = torch.std(x)\n","        return (x - mean)/(std + 10**(-6))  # 0除算を防ぐ\n","\n","\n","class ZCAWhitening():\n","    def __init__(self, epsilon=1e-4, device=\"cuda\"):  # 計算が重いのでGPUを用いる\n","        self.epsilon = epsilon\n","        self.device = device\n","\n","    def fit(self, images):  # 変換行列と平均をデータから計算\n","        x = images[0][0].reshape(1, -1)\n","        self.mean = torch.zeros([1, x.size()[1]]).to(self.device)\n","        con_matrix = torch.zeros([x.size()[1], x.size()[1]]).to(self.device)\n","        for i in range(len(images)):  # 各データについての平均を取る\n","            x = images[i][0].reshape(1, -1).to(self.device)\n","            self.mean += x / len(images)\n","            con_matrix += torch.mm(x.t(), x) / len(images)\n","            if i % 10000 == 0:\n","                print(\"{0}/{1}\".format(i, len(images)))\n","        self.E, self.V = torch.linalg.eigh(con_matrix)  # 固有値分解\n","        self.E = torch.max(self.E, torch.zeros_like(self.E)) # 誤差の影響で負になるのを防ぐ\n","        self.ZCA_matrix = torch.mm(torch.mm(self.V, torch.diag((self.E.squeeze()+self.epsilon)**(-0.5))), self.V.t())\n","        print(\"completed!\")\n","\n","    def __call__(self, x):\n","        size = x.size()\n","        x = x.reshape(1, -1).to(self.device)\n","        x -= self.mean\n","        x = torch.mm(x, self.ZCA_matrix.t())\n","        x = x.reshape(tuple(size))\n","        x = x.to(\"cpu\")\n","        return x\n","\n","\n","# (datasetのクラスを自作したので，このあたりの処理が少し変わっています)\n","\n","zca = ZCAWhitening()\n","zca.fit(trainval_data)\n","\n","val_size = 3000\n","train_data, val_data = torch.utils.data.random_split(trainval_data, [len(trainval_data)-val_size, val_size])  # 訓練データと検証データに分割\n","\n","\n","# 前処理を定義\n","transform_train = transforms.Compose([\n","    transforms.RandomHorizontalFlip(p=0.3),\n","    transforms.RandomCrop(32, padding=(4, 4, 4, 4), padding_mode='constant'),\n","    transforms.ColorJitter(brightness=0.5, contrast=0.5, saturation=0.5),\n","    transforms.ToTensor(),\n","    zca])\n","\n","transform = transforms.Compose([\n","    transforms.ToTensor(),\n","    zca])\n","\n","# データセットに前処理を設定\n","trainval_data.transform = transform_train\n","test_data.transform = transform\n","\n","batch_size = 64\n","\n","dataloader_train = torch.utils.data.DataLoader(\n","    train_data,\n","    batch_size=batch_size,\n","    shuffle=True\n",")\n","\n","dataloader_valid = torch.utils.data.DataLoader(\n","    val_data,\n","    batch_size=batch_size,\n","    shuffle=True\n",")\n","\n","dataloader_test = torch.utils.data.DataLoader(\n","    test_data,\n","    batch_size=batch_size,\n","    shuffle=False\n",")\n"],"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["0/50000\n","10000/50000\n","20000/50000\n","30000/50000\n","40000/50000\n","completed!\n"]}]},{"cell_type":"code","metadata":{"id":"PADQiKNa2snb"},"source":["import torch.nn as nn\n","import torch.optim as optim\n","import torch.autograd as autograd\n","import torch.nn.functional as F\n","\n","rng = np.random.RandomState(1234)\n","random_state = 42\n","device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n","\n","\n","conv_net =nn.Sequential(\n","    nn.Conv2d(3, 32, 3),              # 32x32x3 -> 30x30x32\n","    nn.BatchNorm2d(32),\n","    nn.ReLU(),\n","    nn.AvgPool2d(2),                  # 30x30x32 -> 15x15x32\n","    nn.Conv2d(32, 64, 3),             # 15x15x32 -> 13x13x64\n","    nn.BatchNorm2d(64),\n","    nn.ReLU(),\n","    nn.AvgPool2d(2),                  # 13x13x64 -> 6x6x64\n","    nn.Conv2d(64, 128, 3),            # 6x6x64 -> 4x4x128\n","    nn.BatchNorm2d(128),\n","    nn.ReLU(),\n","    nn.AvgPool2d(2),                  # 4x4x128 -> 2x2x128\n","    nn.Flatten(),\n","    nn.Linear(2*2*128, 256),\n","    nn.ReLU(),\n","    nn.Linear(256, 10)\n",")\n","\n","\n","def init_weights(m):  # Heの初期化\n","    if type(m) == nn.Linear or type(m) == nn.Conv2d:\n","        torch.nn.init.kaiming_normal_(m.weight)\n","        m.bias.data.fill_(0.0)\n","\n","\n","conv_net.apply(init_weights)\n","\n","\n","n_epochs = 25\n","lr = 0.01\n","device = 'cuda'\n","\n","conv_net.to(device)\n","optimizer = optim.Adam(conv_net.parameters(), lr=lr)\n","loss_function = nn.CrossEntropyLoss() "],"execution_count":null,"outputs":[]},{"cell_type":"code","source":["import torch.nn as nn\n","import torch.optim as optim\n","import torch.autograd as autograd\n","import torch.nn.functional as F\n","\n","rng = np.random.RandomState(1234)\n","random_state = 42\n","device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n","\n","class ResBlock(nn.Module):\n","\n","    def __init__(\n","        self,\n","        in_channels,\n","        channels,\n","        kernel=3,\n","        stride=1\n","    ):\n","        super().__init__()\n","        self.conv1 =  nn.Conv2d(in_channels, channels, kernel, padding=1)\n","        self.bn1 = nn.BatchNorm2d(channels)\n","        self.relu = nn.ReLU()\n","        self.conv2 = nn.Conv2d(channels, channels, kernel, padding=1)\n","        self.bn2 = nn.BatchNorm2d(channels)\n","\n","\n","    def forward(self, x):\n","        identity= x\n","        out = self.conv1(x)\n","        out = self.bn1(out)\n","        out = self.relu(out)\n","\n","        out = self.conv2(out)\n","        out = self.bn2(out)\n","\n","        out += identity\n","\n","        out = self.relu(out)\n","\n","        return out\n","\n","conv_net =nn.Sequential(\n","    nn.Conv2d(3,16,1,padding=1), # 32x32x3 -> 32x32x16\n","\n","    ResBlock(16,16),\n","    ResBlock(16,16),\n","    ResBlock(16,16),\n","    ResBlock(16,16),\n","    ResBlock(16,16),\n","    ResBlock(16,16),\n","    ResBlock(16,16),\n","    ResBlock(16,16),\n","    ResBlock(16,16),\n","    nn.Conv2d(16, 32,1,stride=2),  # 32x32x16 -> 16x16x32\n","\n","    ResBlock(32,32),\n","    ResBlock(32,32),\n","    ResBlock(32,32),\n","    ResBlock(32,32),\n","    ResBlock(32,32),\n","    ResBlock(32,32),\n","    ResBlock(32,32),\n","    ResBlock(32,32),\n","    ResBlock(32,32),\n","    nn.Conv2d(32,64,1,stride=2),  # 16x16x32 -> 8x8x64\n","\n","    ResBlock(64,64),\n","    ResBlock(64,64),\n","    ResBlock(64,64),\n","    ResBlock(64,64),\n","    ResBlock(64,64),\n","    ResBlock(64,64),\n","    ResBlock(64,64),\n","    ResBlock(64,64),\n","    ResBlock(64,64),\n","\n","    nn.AdaptiveAvgPool2d((1,1)),\n","    nn.Flatten(),\n","    nn.Linear(64, 10),\n","    #nn.ReLU(),\n","    #nn.Linear(32, 10)\n",")\n","\n","\n","def init_weights(m):  # Heの初期化\n","    if type(m) == nn.Linear or type(m) == nn.Conv2d:\n","        torch.nn.init.kaiming_normal_(m.weight)\n","        m.bias.data.fill_(0.0)\n","\n","\n","conv_net.apply(init_weights)\n","\n","\n","n_epochs = 180\n","lr = 0.01\n","device = 'cuda'\n","\n","conv_net.to(device)\n","optimizer = optim.Adam(conv_net.parameters(), lr=lr)\n","loss_function = nn.CrossEntropyLoss() "],"metadata":{"id":"MFcl4iuk5_qn"},"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"nlOZuLu-328i","executionInfo":{"status":"ok","timestamp":1684612272954,"user_tz":-540,"elapsed":10931180,"user":{"displayName":"村本雅弥","userId":"04864828231714976662"}},"colab":{"base_uri":"https://localhost:8080/"},"outputId":"d31b2195-d66b-4eb2-d8da-4c779353f9b5"},"source":["for epoch in range(n_epochs):\n","    losses_train = []\n","    losses_valid = []\n","\n","    conv_net.train()\n","    n_train = 0\n","    acc_train = 0\n","    for x, t in dataloader_train:\n","        n_train += t.size()[0]\n","\n","        conv_net.zero_grad() \n","\n","        x = x.to(device)\n","        t = t.to(device)\n","\n","        y = conv_net.forward(x)\n","\n","        loss = loss_function(y, t)\n","\n","        loss.backward()\n","\n","        optimizer.step()\n","\n","        pred = y.argmax(1)\n","\n","        acc_train += (pred == t).float().sum().item()\n","        losses_train.append(loss.tolist())\n","\n","    conv_net.eval()\n","    n_val = 0\n","    acc_val = 0\n","    for x, t in dataloader_valid:\n","        n_val += t.size()[0]\n","\n","        x = x.to(device) \n","        t = t.to(device)\n","\n","        y = conv_net.forward(x)\n","\n","        loss = loss_function(y, t)\n","\n","        pred = y.argmax(1)\n","\n","        acc_val += (pred == t).float().sum().item()\n","        losses_valid.append(loss.tolist())\n","\n","\n","    print('EPOCH: {}, Train [Loss: {:.3f}, Accuracy: {:.3f}], Valid [Loss: {:.3f}, Accuracy: {:.3f}]'.format(\n","        epoch,\n","        np.mean(losses_train),\n","        acc_train/n_train,\n","        np.mean(losses_valid),\n","        acc_val/n_val\n","    ))"],"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["EPOCH: 0, Train [Loss: 1.893, Accuracy: 0.318], Valid [Loss: 2.023, Accuracy: 0.359]\n","EPOCH: 1, Train [Loss: 1.300, Accuracy: 0.533], Valid [Loss: 1.249, Accuracy: 0.551]\n","EPOCH: 2, Train [Loss: 1.105, Accuracy: 0.607], Valid [Loss: 1.033, Accuracy: 0.634]\n","EPOCH: 3, Train [Loss: 0.991, Accuracy: 0.649], Valid [Loss: 0.934, Accuracy: 0.666]\n","EPOCH: 4, Train [Loss: 0.894, Accuracy: 0.686], Valid [Loss: 1.013, Accuracy: 0.651]\n","EPOCH: 5, Train [Loss: 0.815, Accuracy: 0.714], Valid [Loss: 0.922, Accuracy: 0.675]\n","EPOCH: 6, Train [Loss: 0.740, Accuracy: 0.742], Valid [Loss: 0.794, Accuracy: 0.731]\n","EPOCH: 7, Train [Loss: 0.685, Accuracy: 0.762], Valid [Loss: 0.695, Accuracy: 0.758]\n","EPOCH: 8, Train [Loss: 0.638, Accuracy: 0.778], Valid [Loss: 0.663, Accuracy: 0.786]\n","EPOCH: 9, Train [Loss: 0.602, Accuracy: 0.793], Valid [Loss: 0.691, Accuracy: 0.765]\n","EPOCH: 10, Train [Loss: 0.571, Accuracy: 0.802], Valid [Loss: 0.631, Accuracy: 0.790]\n","EPOCH: 11, Train [Loss: 0.538, Accuracy: 0.815], Valid [Loss: 1.008, Accuracy: 0.691]\n","EPOCH: 12, Train [Loss: 0.517, Accuracy: 0.822], Valid [Loss: 0.615, Accuracy: 0.794]\n","EPOCH: 13, Train [Loss: 0.492, Accuracy: 0.830], Valid [Loss: 0.567, Accuracy: 0.803]\n","EPOCH: 14, Train [Loss: 0.471, Accuracy: 0.837], Valid [Loss: 0.539, Accuracy: 0.808]\n","EPOCH: 15, Train [Loss: 0.451, Accuracy: 0.844], Valid [Loss: 0.621, Accuracy: 0.793]\n","EPOCH: 16, Train [Loss: 0.441, Accuracy: 0.848], Valid [Loss: 0.613, Accuracy: 0.789]\n","EPOCH: 17, Train [Loss: 0.417, Accuracy: 0.854], Valid [Loss: 0.520, Accuracy: 0.825]\n","EPOCH: 18, Train [Loss: 0.410, Accuracy: 0.857], Valid [Loss: 0.598, Accuracy: 0.788]\n","EPOCH: 19, Train [Loss: 0.392, Accuracy: 0.865], Valid [Loss: 0.546, Accuracy: 0.815]\n","EPOCH: 20, Train [Loss: 0.381, Accuracy: 0.867], Valid [Loss: 0.511, Accuracy: 0.829]\n","EPOCH: 21, Train [Loss: 0.373, Accuracy: 0.870], Valid [Loss: 0.510, Accuracy: 0.825]\n","EPOCH: 22, Train [Loss: 0.356, Accuracy: 0.876], Valid [Loss: 0.516, Accuracy: 0.834]\n","EPOCH: 23, Train [Loss: 0.352, Accuracy: 0.877], Valid [Loss: 0.478, Accuracy: 0.841]\n","EPOCH: 24, Train [Loss: 0.330, Accuracy: 0.884], Valid [Loss: 0.477, Accuracy: 0.847]\n","EPOCH: 25, Train [Loss: 0.324, Accuracy: 0.887], Valid [Loss: 0.658, Accuracy: 0.798]\n","EPOCH: 26, Train [Loss: 0.326, Accuracy: 0.885], Valid [Loss: 0.536, Accuracy: 0.824]\n","EPOCH: 27, Train [Loss: 0.314, Accuracy: 0.890], Valid [Loss: 0.508, Accuracy: 0.842]\n","EPOCH: 28, Train [Loss: 0.301, Accuracy: 0.896], Valid [Loss: 0.506, Accuracy: 0.831]\n","EPOCH: 29, Train [Loss: 0.296, Accuracy: 0.897], Valid [Loss: 0.560, Accuracy: 0.814]\n","EPOCH: 30, Train [Loss: 0.287, Accuracy: 0.898], Valid [Loss: 0.762, Accuracy: 0.774]\n","EPOCH: 31, Train [Loss: 0.277, Accuracy: 0.905], Valid [Loss: 0.527, Accuracy: 0.840]\n","EPOCH: 32, Train [Loss: 0.279, Accuracy: 0.903], Valid [Loss: 0.527, Accuracy: 0.832]\n","EPOCH: 33, Train [Loss: 0.268, Accuracy: 0.907], Valid [Loss: 0.523, Accuracy: 0.842]\n","EPOCH: 34, Train [Loss: 0.265, Accuracy: 0.907], Valid [Loss: 0.482, Accuracy: 0.841]\n","EPOCH: 35, Train [Loss: 0.262, Accuracy: 0.908], Valid [Loss: 0.522, Accuracy: 0.839]\n","EPOCH: 36, Train [Loss: 0.249, Accuracy: 0.910], Valid [Loss: 0.455, Accuracy: 0.853]\n","EPOCH: 37, Train [Loss: 0.243, Accuracy: 0.916], Valid [Loss: 0.511, Accuracy: 0.842]\n","EPOCH: 38, Train [Loss: 0.237, Accuracy: 0.919], Valid [Loss: 0.425, Accuracy: 0.856]\n","EPOCH: 39, Train [Loss: 0.237, Accuracy: 0.918], Valid [Loss: 0.400, Accuracy: 0.867]\n","EPOCH: 40, Train [Loss: 0.228, Accuracy: 0.920], Valid [Loss: 0.414, Accuracy: 0.868]\n","EPOCH: 41, Train [Loss: 0.226, Accuracy: 0.921], Valid [Loss: 0.413, Accuracy: 0.869]\n","EPOCH: 42, Train [Loss: 0.224, Accuracy: 0.921], Valid [Loss: 0.442, Accuracy: 0.870]\n","EPOCH: 43, Train [Loss: 0.218, Accuracy: 0.924], Valid [Loss: 0.460, Accuracy: 0.856]\n","EPOCH: 44, Train [Loss: 0.215, Accuracy: 0.925], Valid [Loss: 0.437, Accuracy: 0.866]\n","EPOCH: 45, Train [Loss: 0.207, Accuracy: 0.928], Valid [Loss: 0.432, Accuracy: 0.869]\n","EPOCH: 46, Train [Loss: 0.206, Accuracy: 0.928], Valid [Loss: 0.465, Accuracy: 0.847]\n","EPOCH: 47, Train [Loss: 0.204, Accuracy: 0.930], Valid [Loss: 0.436, Accuracy: 0.868]\n","EPOCH: 48, Train [Loss: 0.199, Accuracy: 0.930], Valid [Loss: 0.492, Accuracy: 0.855]\n","EPOCH: 49, Train [Loss: 0.190, Accuracy: 0.933], Valid [Loss: 0.421, Accuracy: 0.873]\n","EPOCH: 50, Train [Loss: 0.186, Accuracy: 0.936], Valid [Loss: 0.491, Accuracy: 0.855]\n","EPOCH: 51, Train [Loss: 0.190, Accuracy: 0.933], Valid [Loss: 0.412, Accuracy: 0.878]\n","EPOCH: 52, Train [Loss: 0.185, Accuracy: 0.936], Valid [Loss: 0.450, Accuracy: 0.866]\n","EPOCH: 53, Train [Loss: 0.186, Accuracy: 0.936], Valid [Loss: 0.451, Accuracy: 0.858]\n","EPOCH: 54, Train [Loss: 0.180, Accuracy: 0.937], Valid [Loss: 0.457, Accuracy: 0.861]\n","EPOCH: 55, Train [Loss: 0.171, Accuracy: 0.940], Valid [Loss: 0.446, Accuracy: 0.869]\n","EPOCH: 56, Train [Loss: 0.172, Accuracy: 0.940], Valid [Loss: 0.508, Accuracy: 0.843]\n","EPOCH: 57, Train [Loss: 0.172, Accuracy: 0.939], Valid [Loss: 0.474, Accuracy: 0.853]\n","EPOCH: 58, Train [Loss: 0.171, Accuracy: 0.939], Valid [Loss: 0.422, Accuracy: 0.874]\n","EPOCH: 59, Train [Loss: 0.167, Accuracy: 0.942], Valid [Loss: 0.520, Accuracy: 0.856]\n","EPOCH: 60, Train [Loss: 0.162, Accuracy: 0.943], Valid [Loss: 0.518, Accuracy: 0.859]\n","EPOCH: 61, Train [Loss: 0.164, Accuracy: 0.943], Valid [Loss: 0.373, Accuracy: 0.881]\n","EPOCH: 62, Train [Loss: 0.159, Accuracy: 0.944], Valid [Loss: 0.488, Accuracy: 0.858]\n","EPOCH: 63, Train [Loss: 0.158, Accuracy: 0.945], Valid [Loss: 0.498, Accuracy: 0.863]\n","EPOCH: 64, Train [Loss: 0.156, Accuracy: 0.946], Valid [Loss: 0.417, Accuracy: 0.879]\n","EPOCH: 65, Train [Loss: 0.152, Accuracy: 0.947], Valid [Loss: 0.412, Accuracy: 0.878]\n","EPOCH: 66, Train [Loss: 0.156, Accuracy: 0.947], Valid [Loss: 0.407, Accuracy: 0.879]\n","EPOCH: 67, Train [Loss: 0.146, Accuracy: 0.950], Valid [Loss: 0.454, Accuracy: 0.867]\n","EPOCH: 68, Train [Loss: 0.146, Accuracy: 0.949], Valid [Loss: 0.413, Accuracy: 0.871]\n","EPOCH: 69, Train [Loss: 0.141, Accuracy: 0.951], Valid [Loss: 0.478, Accuracy: 0.860]\n","EPOCH: 70, Train [Loss: 0.145, Accuracy: 0.950], Valid [Loss: 0.426, Accuracy: 0.879]\n","EPOCH: 71, Train [Loss: 0.142, Accuracy: 0.951], Valid [Loss: 0.471, Accuracy: 0.866]\n","EPOCH: 72, Train [Loss: 0.136, Accuracy: 0.953], Valid [Loss: 0.567, Accuracy: 0.849]\n","EPOCH: 73, Train [Loss: 0.139, Accuracy: 0.952], Valid [Loss: 0.466, Accuracy: 0.871]\n","EPOCH: 74, Train [Loss: 0.137, Accuracy: 0.951], Valid [Loss: 0.501, Accuracy: 0.861]\n","EPOCH: 75, Train [Loss: 0.135, Accuracy: 0.953], Valid [Loss: 0.431, Accuracy: 0.882]\n","EPOCH: 76, Train [Loss: 0.133, Accuracy: 0.954], Valid [Loss: 0.442, Accuracy: 0.871]\n","EPOCH: 77, Train [Loss: 0.127, Accuracy: 0.957], Valid [Loss: 0.460, Accuracy: 0.876]\n","EPOCH: 78, Train [Loss: 0.134, Accuracy: 0.954], Valid [Loss: 0.401, Accuracy: 0.879]\n","EPOCH: 79, Train [Loss: 0.129, Accuracy: 0.955], Valid [Loss: 0.429, Accuracy: 0.870]\n","EPOCH: 80, Train [Loss: 0.131, Accuracy: 0.954], Valid [Loss: 0.466, Accuracy: 0.869]\n","EPOCH: 81, Train [Loss: 0.123, Accuracy: 0.957], Valid [Loss: 0.476, Accuracy: 0.867]\n","EPOCH: 82, Train [Loss: 0.127, Accuracy: 0.956], Valid [Loss: 0.493, Accuracy: 0.860]\n","EPOCH: 83, Train [Loss: 0.123, Accuracy: 0.957], Valid [Loss: 0.467, Accuracy: 0.875]\n","EPOCH: 84, Train [Loss: 0.120, Accuracy: 0.959], Valid [Loss: 0.431, Accuracy: 0.875]\n","EPOCH: 85, Train [Loss: 0.115, Accuracy: 0.960], Valid [Loss: 0.485, Accuracy: 0.865]\n","EPOCH: 86, Train [Loss: 0.125, Accuracy: 0.957], Valid [Loss: 0.444, Accuracy: 0.869]\n","EPOCH: 87, Train [Loss: 0.115, Accuracy: 0.961], Valid [Loss: 0.425, Accuracy: 0.874]\n","EPOCH: 88, Train [Loss: 0.120, Accuracy: 0.959], Valid [Loss: 0.444, Accuracy: 0.881]\n","EPOCH: 89, Train [Loss: 0.114, Accuracy: 0.961], Valid [Loss: 0.488, Accuracy: 0.876]\n","EPOCH: 90, Train [Loss: 0.112, Accuracy: 0.962], Valid [Loss: 0.466, Accuracy: 0.871]\n","EPOCH: 91, Train [Loss: 0.114, Accuracy: 0.959], Valid [Loss: 0.417, Accuracy: 0.881]\n","EPOCH: 92, Train [Loss: 0.115, Accuracy: 0.960], Valid [Loss: 0.478, Accuracy: 0.859]\n","EPOCH: 93, Train [Loss: 0.112, Accuracy: 0.960], Valid [Loss: 0.532, Accuracy: 0.874]\n","EPOCH: 94, Train [Loss: 0.112, Accuracy: 0.961], Valid [Loss: 0.469, Accuracy: 0.872]\n","EPOCH: 95, Train [Loss: 0.111, Accuracy: 0.961], Valid [Loss: 0.539, Accuracy: 0.855]\n","EPOCH: 96, Train [Loss: 0.104, Accuracy: 0.964], Valid [Loss: 0.430, Accuracy: 0.880]\n","EPOCH: 97, Train [Loss: 0.106, Accuracy: 0.963], Valid [Loss: 0.492, Accuracy: 0.875]\n","EPOCH: 98, Train [Loss: 0.111, Accuracy: 0.961], Valid [Loss: 0.423, Accuracy: 0.881]\n","EPOCH: 99, Train [Loss: 0.105, Accuracy: 0.963], Valid [Loss: 0.481, Accuracy: 0.870]\n","EPOCH: 100, Train [Loss: 0.103, Accuracy: 0.964], Valid [Loss: 0.453, Accuracy: 0.873]\n","EPOCH: 101, Train [Loss: 0.106, Accuracy: 0.963], Valid [Loss: 0.415, Accuracy: 0.886]\n","EPOCH: 102, Train [Loss: 0.102, Accuracy: 0.965], Valid [Loss: 0.454, Accuracy: 0.877]\n","EPOCH: 103, Train [Loss: 0.102, Accuracy: 0.963], Valid [Loss: 0.507, Accuracy: 0.857]\n","EPOCH: 104, Train [Loss: 0.100, Accuracy: 0.965], Valid [Loss: 0.476, Accuracy: 0.876]\n","EPOCH: 105, Train [Loss: 0.104, Accuracy: 0.964], Valid [Loss: 0.443, Accuracy: 0.880]\n","EPOCH: 106, Train [Loss: 0.098, Accuracy: 0.967], Valid [Loss: 0.443, Accuracy: 0.878]\n","EPOCH: 107, Train [Loss: 0.102, Accuracy: 0.964], Valid [Loss: 0.488, Accuracy: 0.874]\n","EPOCH: 108, Train [Loss: 0.095, Accuracy: 0.967], Valid [Loss: 0.588, Accuracy: 0.860]\n","EPOCH: 109, Train [Loss: 0.096, Accuracy: 0.966], Valid [Loss: 0.463, Accuracy: 0.878]\n","EPOCH: 110, Train [Loss: 0.095, Accuracy: 0.968], Valid [Loss: 0.509, Accuracy: 0.867]\n","EPOCH: 111, Train [Loss: 0.099, Accuracy: 0.966], Valid [Loss: 0.507, Accuracy: 0.878]\n","EPOCH: 112, Train [Loss: 0.095, Accuracy: 0.967], Valid [Loss: 0.514, Accuracy: 0.876]\n","EPOCH: 113, Train [Loss: 0.096, Accuracy: 0.966], Valid [Loss: 0.528, Accuracy: 0.862]\n","EPOCH: 114, Train [Loss: 0.091, Accuracy: 0.967], Valid [Loss: 0.463, Accuracy: 0.882]\n","EPOCH: 115, Train [Loss: 0.094, Accuracy: 0.968], Valid [Loss: 0.457, Accuracy: 0.874]\n","EPOCH: 116, Train [Loss: 0.092, Accuracy: 0.968], Valid [Loss: 0.450, Accuracy: 0.891]\n","EPOCH: 117, Train [Loss: 0.090, Accuracy: 0.969], Valid [Loss: 0.486, Accuracy: 0.876]\n","EPOCH: 118, Train [Loss: 0.092, Accuracy: 0.968], Valid [Loss: 0.487, Accuracy: 0.871]\n","EPOCH: 119, Train [Loss: 0.088, Accuracy: 0.969], Valid [Loss: 0.475, Accuracy: 0.878]\n","EPOCH: 120, Train [Loss: 0.091, Accuracy: 0.969], Valid [Loss: 0.515, Accuracy: 0.867]\n","EPOCH: 121, Train [Loss: 0.091, Accuracy: 0.970], Valid [Loss: 0.484, Accuracy: 0.876]\n","EPOCH: 122, Train [Loss: 0.088, Accuracy: 0.970], Valid [Loss: 0.441, Accuracy: 0.878]\n","EPOCH: 123, Train [Loss: 0.085, Accuracy: 0.971], Valid [Loss: 0.580, Accuracy: 0.865]\n","EPOCH: 124, Train [Loss: 0.088, Accuracy: 0.970], Valid [Loss: 0.584, Accuracy: 0.857]\n","EPOCH: 125, Train [Loss: 0.087, Accuracy: 0.970], Valid [Loss: 0.501, Accuracy: 0.873]\n","EPOCH: 126, Train [Loss: 0.083, Accuracy: 0.971], Valid [Loss: 0.452, Accuracy: 0.886]\n","EPOCH: 127, Train [Loss: 0.086, Accuracy: 0.971], Valid [Loss: 0.518, Accuracy: 0.880]\n","EPOCH: 128, Train [Loss: 0.086, Accuracy: 0.970], Valid [Loss: 0.486, Accuracy: 0.882]\n","EPOCH: 129, Train [Loss: 0.082, Accuracy: 0.971], Valid [Loss: 0.444, Accuracy: 0.883]\n","EPOCH: 130, Train [Loss: 0.081, Accuracy: 0.973], Valid [Loss: 0.507, Accuracy: 0.869]\n","EPOCH: 131, Train [Loss: 0.082, Accuracy: 0.971], Valid [Loss: 0.527, Accuracy: 0.875]\n","EPOCH: 132, Train [Loss: 0.079, Accuracy: 0.972], Valid [Loss: 0.464, Accuracy: 0.878]\n","EPOCH: 133, Train [Loss: 0.082, Accuracy: 0.972], Valid [Loss: 0.486, Accuracy: 0.882]\n","EPOCH: 134, Train [Loss: 0.088, Accuracy: 0.970], Valid [Loss: 0.439, Accuracy: 0.881]\n","EPOCH: 135, Train [Loss: 0.081, Accuracy: 0.971], Valid [Loss: 0.416, Accuracy: 0.887]\n","EPOCH: 136, Train [Loss: 0.081, Accuracy: 0.973], Valid [Loss: 0.531, Accuracy: 0.874]\n","EPOCH: 137, Train [Loss: 0.079, Accuracy: 0.973], Valid [Loss: 0.516, Accuracy: 0.875]\n","EPOCH: 138, Train [Loss: 0.077, Accuracy: 0.973], Valid [Loss: 0.434, Accuracy: 0.887]\n","EPOCH: 139, Train [Loss: 0.077, Accuracy: 0.973], Valid [Loss: 0.473, Accuracy: 0.879]\n","EPOCH: 140, Train [Loss: 0.076, Accuracy: 0.974], Valid [Loss: 0.482, Accuracy: 0.891]\n","EPOCH: 141, Train [Loss: 0.078, Accuracy: 0.973], Valid [Loss: 0.557, Accuracy: 0.876]\n","EPOCH: 142, Train [Loss: 0.078, Accuracy: 0.973], Valid [Loss: 0.411, Accuracy: 0.888]\n","EPOCH: 143, Train [Loss: 0.077, Accuracy: 0.973], Valid [Loss: 0.506, Accuracy: 0.880]\n","EPOCH: 144, Train [Loss: 0.079, Accuracy: 0.973], Valid [Loss: 0.457, Accuracy: 0.886]\n","EPOCH: 145, Train [Loss: 0.075, Accuracy: 0.974], Valid [Loss: 0.512, Accuracy: 0.881]\n","EPOCH: 146, Train [Loss: 0.074, Accuracy: 0.974], Valid [Loss: 0.587, Accuracy: 0.864]\n","EPOCH: 147, Train [Loss: 0.078, Accuracy: 0.973], Valid [Loss: 0.454, Accuracy: 0.879]\n","EPOCH: 148, Train [Loss: 0.074, Accuracy: 0.974], Valid [Loss: 0.507, Accuracy: 0.880]\n","EPOCH: 149, Train [Loss: 0.076, Accuracy: 0.975], Valid [Loss: 0.424, Accuracy: 0.888]\n","EPOCH: 150, Train [Loss: 0.072, Accuracy: 0.975], Valid [Loss: 0.455, Accuracy: 0.887]\n","EPOCH: 151, Train [Loss: 0.076, Accuracy: 0.974], Valid [Loss: 0.490, Accuracy: 0.879]\n","EPOCH: 152, Train [Loss: 0.073, Accuracy: 0.975], Valid [Loss: 0.462, Accuracy: 0.886]\n","EPOCH: 153, Train [Loss: 0.075, Accuracy: 0.974], Valid [Loss: 0.521, Accuracy: 0.879]\n","EPOCH: 154, Train [Loss: 0.071, Accuracy: 0.976], Valid [Loss: 0.535, Accuracy: 0.879]\n","EPOCH: 155, Train [Loss: 0.067, Accuracy: 0.977], Valid [Loss: 0.487, Accuracy: 0.884]\n","EPOCH: 156, Train [Loss: 0.074, Accuracy: 0.975], Valid [Loss: 0.484, Accuracy: 0.884]\n","EPOCH: 157, Train [Loss: 0.074, Accuracy: 0.975], Valid [Loss: 0.438, Accuracy: 0.887]\n","EPOCH: 158, Train [Loss: 0.067, Accuracy: 0.977], Valid [Loss: 0.431, Accuracy: 0.885]\n","EPOCH: 159, Train [Loss: 0.070, Accuracy: 0.976], Valid [Loss: 0.496, Accuracy: 0.876]\n","EPOCH: 160, Train [Loss: 0.072, Accuracy: 0.975], Valid [Loss: 0.467, Accuracy: 0.883]\n","EPOCH: 161, Train [Loss: 0.069, Accuracy: 0.976], Valid [Loss: 0.527, Accuracy: 0.876]\n","EPOCH: 162, Train [Loss: 0.072, Accuracy: 0.975], Valid [Loss: 0.531, Accuracy: 0.877]\n","EPOCH: 163, Train [Loss: 0.066, Accuracy: 0.978], Valid [Loss: 0.490, Accuracy: 0.881]\n","EPOCH: 164, Train [Loss: 0.072, Accuracy: 0.976], Valid [Loss: 0.474, Accuracy: 0.888]\n","EPOCH: 165, Train [Loss: 0.068, Accuracy: 0.977], Valid [Loss: 0.473, Accuracy: 0.890]\n","EPOCH: 166, Train [Loss: 0.068, Accuracy: 0.977], Valid [Loss: 0.523, Accuracy: 0.880]\n","EPOCH: 167, Train [Loss: 0.067, Accuracy: 0.977], Valid [Loss: 0.506, Accuracy: 0.875]\n","EPOCH: 168, Train [Loss: 0.069, Accuracy: 0.976], Valid [Loss: 0.511, Accuracy: 0.877]\n","EPOCH: 169, Train [Loss: 0.062, Accuracy: 0.979], Valid [Loss: 0.489, Accuracy: 0.889]\n","EPOCH: 170, Train [Loss: 0.066, Accuracy: 0.977], Valid [Loss: 0.527, Accuracy: 0.871]\n","EPOCH: 171, Train [Loss: 0.067, Accuracy: 0.978], Valid [Loss: 0.510, Accuracy: 0.880]\n","EPOCH: 172, Train [Loss: 0.066, Accuracy: 0.977], Valid [Loss: 0.545, Accuracy: 0.878]\n","EPOCH: 173, Train [Loss: 0.065, Accuracy: 0.978], Valid [Loss: 0.460, Accuracy: 0.890]\n","EPOCH: 174, Train [Loss: 0.065, Accuracy: 0.978], Valid [Loss: 0.534, Accuracy: 0.880]\n","EPOCH: 175, Train [Loss: 0.066, Accuracy: 0.978], Valid [Loss: 0.445, Accuracy: 0.888]\n","EPOCH: 176, Train [Loss: 0.065, Accuracy: 0.978], Valid [Loss: 0.441, Accuracy: 0.888]\n","EPOCH: 177, Train [Loss: 0.069, Accuracy: 0.977], Valid [Loss: 0.505, Accuracy: 0.883]\n","EPOCH: 178, Train [Loss: 0.061, Accuracy: 0.979], Valid [Loss: 0.506, Accuracy: 0.878]\n","EPOCH: 179, Train [Loss: 0.065, Accuracy: 0.978], Valid [Loss: 0.519, Accuracy: 0.889]\n"]}]},{"cell_type":"code","metadata":{"id":"Yq3scS5j4Rt2"},"source":["conv_net.eval()\n","\n","t_pred = []\n","for x in dataloader_test:\n","\n","    x = x.to(device)\n","\n","    # 順伝播\n","    y = conv_net.forward(x)\n","\n","    # モデルの出力を予測値のスカラーに変換\n","    pred = y.argmax(1).tolist()\n","\n","    t_pred.extend(pred)\n","\n","submission = pd.Series(t_pred, name='label')\n","submission.to_csv('drive/MyDrive/Colab Notebooks/DeepLearning/Lecture05/submission_pred.csv', header=True, index_label='id')\n","#submission.to_csv('drive/MyDrive/Colab Notebooks/DLBasics2023_colab/Lecture05/submission_pred.csv', header=True, index_label='id')"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"73f8DjqTCoTL"},"source":[],"execution_count":null,"outputs":[]}]}